### background

现有的计算机网络对用户开放大量数据的同时，也遭受着网络攻击。大部分的攻击具有一定的攻击模式和特征，对这些攻击模式特征进行提取、归类和学习能够有效地预防cyber-security breaches，而对网络安全事件流中网络攻击存在的可能性预测和对攻击者后续动态预测主要有两个方面的研究。

一方面，虽然网络上开放的数据集很多，但是由于数据的隐私性和收集困难度，数据的利用效率并不高。在被有限的数据集困扰，无法扩充数据集的条件下，如何更好地利用现有数据进行cyber-security breaches预测和网络安全防御是一个重要的研究课题。对现有数据进行预处理、数据融合能够有效地提高网络攻击事件预测和网络攻击者的活动预测。现有的论文中对数据融合已经有了一定的研究，杰克·霍根和尼尔·亚当斯实现了来自多个来源和实体的数据的适当融合以提高预测准确性。这些是基于前人对缺乏标签下的网络安全特征学习和分类器选择研究的先例。

另一方面，除了对现有的网络安全攻击进行特征提取并防御之外，预测攻击者的下一动向更加重要，在掌握了攻击者的攻击特征后，根据相同网络攻击轨迹，对其下一步动向进行预测从而做到防患网络攻击的作用。现有方法通过构建主机通信图提取基本特征进行学习，以发现危害主机的恶意侧移行为。



### motivation

在多源网络安全事件中提取攻击者的特征来预测攻击者的攻击倾向以及发掘未被探测出的攻击者的相关现存研究很多。这些研究基于某些单个方面，同时也存在一定的局限性。

在数据预处理和融合方面，由于网络安全数据集信息的不完整性和隐私保护政策，现有大多数数据集利用率并不高。在现有有限数据集的情况下，怎样通过有限数据的预处理和融合提高模型预测效率是一个重要的研究方向。

在模型预测方面，由于攻击活动明显少于正常网络活动，数据的不平衡性会降低预测的精度。可以通过基于阳性和未标记数据的半监督分类等方法改进现有的学习模式，这是接下来想要研究的课题。

所以，结合上述两个特征，在多源网络安全事件中对信息进行提取攻击者的攻击特征的研究并不是十分地充分。同时，运用多源数据融合进行攻击者特征提取的研究很少，所以，本文从多源的网络安全事件中，运用各种参考的论文提取特征方式获得尽量多的攻击者特征模式，用以挖掘出更多的攻击者和预测更多的攻击事件。

### preliminary methodology

该课题的研究主要基于一份数据集，This data set represents 58 consecutive days of de-identified event data collected from five sources within Los Alamos National Laboratory’s corporate, internal computer network.

其中包括了四维网络安全事件信息和一维redteam数据，即从身份验证数据中，已被检测出标记为攻击行为的数据。

首先，对已被标识为危害事件的数据进行分析得到一些表征特征。然后结合其余四维的数据特征进行推测，从数据中提取更多攻击特征，这里用到了一些统计学特征提取、异常检测算法和图网络构建来提取攻击特征。在聚合所有提取的攻击模式特征之后执行特征选择，以确定最终的复合特征并自定义结构体描述攻击模式。最后运用模型到数据集中，找出未被发现的redteam成员。同时，为了验证模型的准确度，可以以已经被定义为redteam的成员作为指标，根据模型找出的被标记redteam成员占总数的比例，作为特征模型好坏的观测指标。也可以以时间为维度，预测攻击事件的准确率作为指标。最后，由于redteam标记了只标记了前28天的数据，还可以用模型预测后28天的攻击事件



### preliminary model/algorithm

基于上一次实验报告，基本上有了一个比较完善的算法体系和结构思路。这一段初步模型和算法主要介绍整体的对数据集预处理算法以及特征模型整合和最后攻击特征模型验证的思路及具体实施策略。



数据集主要包含四维数据和一份redteam攻击事件文件。

本小节主要对五份数据集构成进行分析并列出处理每份数据集方法和算法模型。后四份事件主要结合Redteam攻击事件融合进行特征提取。

其中redteam事件组成如表1，包含从身份验证数据中，已被检测出标记为攻击行为的数据。从redteam文件中主要提取出一些攻击者的特征，例如：最活跃的攻击者、攻击者最常攻击对象、攻击者活跃时间分布等。这些攻击特征可以直接用统计的方式得出。

身份验证事件大多数为正常的服务请求数据，只有少部分数据是带有攻击事件的数据。而redteam数据是从身份验证数据中提取的，所以综合redteam数据和身份验证数据两份数据，只需要提取出身份验证数据中包含攻击事件的身份验证信息即可形成几个攻击特征。

网络流事件表示从网络内的中央路由器收集的网络流事件。

分析与redteam中攻击者相关的网络流特征，可以找出攻击者常用的端口号以及攻击者习惯使用的协议、发送的packet和bytes数量作为特征。从时间维度上还能找出攻击者在攻击时间段附近的网络流状态作为攻击特征。

因为网络流数据中大部分数据属于正常数据，只有少部分属于可能存在攻击的事件，所以在数据流数据集中还可以运用到异常检测算法来检测不正常的数据以找出攻击特征。



DNS数据表示从网络内的中央DNS服务器收集的域名服务（DNS）查找事件，在给定时间显示源计算机针对已解析计算机的DNS查找，并表示从源计算机到目标计算机的可能的网络连接。

根据域名服务查找信息可以获取攻击者对被攻击者发起域名服务请求的数量与时间段关系获得攻击特征。



进程文件包含了单个计算机或服务器上的进程信息。在结合redteam文件后，可以找出经常发起攻击的计算机或服务器，监控其发起攻击时间段的进程状态变化，可以找出攻击者常用的进程号和进程执行时间。



四维数据

- 身份验证事件（攻击事件占少数，最后处理）
- 单个计算机进程事件（统计学特征）
- 网络流事件（异常检测算法）
- DNS查找事件（构建通信图，DNS边界特征，拓扑结构特征作为单个计算机结点特征->攻击者的特征值）



上述提取特征的模式基于统计学特征，将这些特征进行简单编码形成攻击者的攻击特征向量，此时这些攻击特征已经可以进行攻击者的查找，但是这些攻击特征可能与实际的攻击者行为有一定出入，所以还可以从时间和空间维度对攻击者的行为进行预判。

所以这里打算参考一篇论文，用基于网络嵌入的方法识别内部网络中潜在的恶意横向移动行为。从五份数据集中提取出主机通信图，其有向边可以作为特征。用网络嵌入方法，将某一点与周围的要素聚合在一起以形成复合要素。在聚合之后执行特征选择，并反复进行学习选择过程以获得最终的复合特征。通过去噪自动编码器，提取具有较低维的训练矢量的最终特征可以进行恶意主机识别，也可以指示恶意横向移动。 具体实现模式见图2.



运用特征模型到数据集中，找出未被发现的redteam成员。

同时，为了验证模型的准确度，可以以已经被定义为redteam的成员作为指标。根据模型找出的被标记redteam成员占总数的比例，作为特征模型好坏的观测指标。也可以以时间为维度，预测攻击事件的准确率作为指标。

最后，由于redteam标记了只标记了前28天的数据，还可以用模型预测后28天的攻击事件。



### preliminary implementation

首先是对redteam文件的单独处理，处理了所有攻击事件，提取出了每个攻击者的攻击对象及其对每个攻击对象的攻击次数。从数据中可以发现被检测到的攻击事件中只有四个攻击发起者，其中来自C17693的攻击次数多达701次而其余攻击者的攻击次数相比较下比较少，攻击者攻击次数分布见图3。

其次，多数受害者其实只遭受了一次攻击，而部分受害者为其主要目标。不同攻击者的攻击对象有重合也有不同。



DNS服务主要包含了源计算机对目标计算机的域名服务请求，从请求中可以看出攻击者对被攻击者在攻击事件时间段附近是否存在频繁的域名服务请求行为来进行攻击特征提取。

从redteam文件中获取了一个重要信息就是标记为攻击者的信息。同时获取的还有被攻击者的计算机编号信息，从DNS文件中查找出攻击者对受害者请求过的域名服务，包含所有时间线上的所有相关域名请求，主要聚焦于域名请求服务次数与攻击者与被攻击者的攻击次数和攻击可能性进行关系分析。调用pyhon自带的networkx库来构建有向图进行可视化处理。

这里原本想构建出所有DNS请求信息并用不同颜色区分可能的正常请求和攻击请求，但是由于DNS文件过大，构成的图结构十分复杂且不清晰，所以采用了只标记出攻击者和被攻击者的方式来可视化攻击者对被攻击者的DNS请求次数变化。

图中红色为攻击者，蓝色为被攻击对象，有向图的边上的权重代表了攻击者对被攻击者发起的DNS域名服务请求次数。

举例分析，下图为某一个攻击者对被攻击者发起攻击的次数统计。



图中信息结合redteam数据分析中得出的攻击者与攻击对象之间的攻击次数可以看出，C612，C457，C625，C1029都是频繁被发起DNS域名服务请求的对象，且他们也是被C19932主要攻击的对象。所以可以得出一个结论：攻击者会对被攻击者发起多次DNS服务请求以达到其攻击目的，这可以作为一项攻击特征。



网络流大部分数据都是正常的网络数据流通，而只有少部分作为异常的网络流数据，这些数据往往可能成为攻击者发起攻击的一个重要特征指标。但是运用统计的方法获得数据效率肯定比较低下而且会遗漏很多异常数据状态。

所以，这里采用了异常检测的算法去检测网络流数据中不正常的部分。异常检测算法有很多种，比较适合网络流数据检测的算法是孤立森林算法，所以通过查阅资料运用孤立森林算法去检测网络流数据。

孤立森林算法基于划分思想，其思想是：假设用一个随机超平面来split data space, 切一次可以生成两个子空间。之后再继续用一个随机超平面来切割每个子空间，循环下去，直到每子空间里面只有一个数据点为止。直观上来讲，那些密度很高的簇是可以被切很多次才会停止切割，但是那些密度很低的点很容易很早的就停到一个子空间了。所以可以轻松找到密度低的点作为异常点，也就是网络流中的异常数据。其伪代码如下：



由于数据集过大，所以目前还未得到具体的运行结果，计划采用分割数据集进行按照时间段的顺序得到结果。

### preliminary results

从redteam文件中提取出了一些攻击者的特征，例如：最活跃的攻击者、攻击者最常攻击对象、攻击者活跃时间分布……

结合redteam和dns文件，得出攻击者对其攻击对象会多次发起域名服务请求的特征，同时，可以根据这一特征，标记出更多的攻击者（？存疑）



### next step

后续对剩下的数据进行方法论中的特征提取，同时用数据融合和实体融合，对五张表格进行合并处理。

其次，构建逻辑主机通信图，使用 DeepGL 框架中提出的网络嵌入方法，将要素与邻居的要素聚合在一起以形成复合要素。在聚合之后执行特征选择，并反复进行学习选择过程以获得最终的复合特征。

先使用上述方法得到的攻击特征进行结果预测，观测指标是否比较令人满意，若会检测出很多非攻击者的对象，则需要继续挖掘特征。
